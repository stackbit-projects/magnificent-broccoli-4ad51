---
title: The Manifesto
subtitle: "At Einst.AI, We're embracing the meta universe and consider ourselves a meta-learning enterprise that is model-agnostic, in the sense that we're pretty compatible with any model trained with stochastic gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning."
image: /images/Transparent.png
image_alt: Team members in a conference room
seo:
  title: About Us
  description: This is the about page
  extra:
    - name: 'og:type'
      value: website
      keyName: property
    - name: 'og:title'
      value: About Us
      keyName: property
    - name: 'og:description'
      value: This is the about page
      keyName: property
    - name: 'og:image'
      value: images/about.jpg
      keyName: property
      relativeUrl: true
    - name: 'twitter:card'
      value: summary_large_image
    - name: 'twitter:title'
      value: About Us
    - name: 'twitter:description'
      value: This is the about page
    - name: 'twitter:image'
      value: images/about.jpg
      relativeUrl: true
layout: PostLayout
---
Einst.AI uses *domain randomization *to train in a very diverse set of simulated environments that enables transfer to the real world. Domain randomization is the extension of data augmentation, which has been used in computer vision since the inception of convolutional networks, from data sets to simulators. Randomizing many aspects of the simulation that do not match the real world forces the learned model to be robust to these variations.

Distractions can look technically similar to domain randomization but distractions are part of the problem that the agent has to solve rather than part of the solution. As a result, the agent does not have control over distractions, i.e. cannot affect these distractions, cannot arbitrarily sample more of them, and has to handle them during evaluation.

The magnitude of each distraction type can be controlled by a “difficulty magnitude” scalar between 0 and 1. Distractions can be set to either change during episodes or change only between episodes, which we will refer to as *dynamic *and *static *settings, respectively.

<h3>Transformer Models with IMAGINATION</h3>

Different from such a database-dependent tree encoding, our zero-shot encoding uses a filtered stateless hash-tree-based encoding where features of nodes are database-independent (i.e., they can be derived from any database at hand). As a result, queries over different databases can be expressed as input to einst.ai. Domain randomization is the extension of data augmentation, which has been used in computer vision since the inception of convolutional networks [17], from data sets to simulators. Randomizing many aspects of the simulation that do not match the real world forces the learned model to be robust to these variations.

Distractions, which this paper focuses on, can look techni- cally similar to domain randomization but distractions as we define them here are part of the problem that the agent has to solve rather than part of the solution. As a result, the agent does not have control over distractions, i.e. cannot affect these distractions, cannot arbitrarily sample more of them, and has to handle them during evaluation.

### 